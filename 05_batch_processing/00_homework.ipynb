{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00bc6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371aa9da-cf85-4d33-ba02-3abb2efbec26",
   "metadata": {},
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0833432d-48de-40fd-a4d4-f0d3fbf0d148",
   "metadata": {},
   "source": [
    "**Q1: Spark version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7174f4df-e540-4a2e-ae98-96bf76edd9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d99f11c5-9554-4831-8642-7f3be5a39313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-07 02:09:52--  https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-10.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 2600:9000:26df:b000:b:20a5:b140:21, 2600:9000:26df:d800:b:20a5:b140:21, 2600:9000:26df:6e00:b:20a5:b140:21, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|2600:9000:26df:b000:b:20a5:b140:21|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18344035 (17M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘fhv_tripdata_2019-10.parquet’\n",
      "\n",
      "fhv_tripdata_2019-1 100%[===================>]  17,49M  31,2MB/s    in 0,6s    \n",
      "\n",
      "2024-03-07 02:09:53 (31,2 MB/s) - ‘fhv_tripdata_2019-10.parquet’ saved [18344035/18344035]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2019-10.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5236cebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 d4m d4m 18M lip 18  2022 fhv_tripdata_2019-10.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh fhv_tripdata_2019-10.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a3399a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .parquet('fhv_tripdata_2019-10.parquet')\n",
    "\n",
    "df = df.repartition(6)\n",
    "df.write.parquet('fhv/2019/10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc23731-47fc-4740-81cf-97f8bf09d72e",
   "metadata": {},
   "source": [
    "**Q2: Partition size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68bc8b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 39M\n",
      "-rw-r--r-- 1 d4m d4m 6,4M mar  7 02:17 part-00000-1696d466-562a-4717-bc0c-78e0e6cc1ae9-c000.snappy.parquet\n",
      "-rw-r--r-- 1 d4m d4m 6,4M mar  7 02:17 part-00001-1696d466-562a-4717-bc0c-78e0e6cc1ae9-c000.snappy.parquet\n",
      "-rw-r--r-- 1 d4m d4m 6,4M mar  7 02:17 part-00002-1696d466-562a-4717-bc0c-78e0e6cc1ae9-c000.snappy.parquet\n",
      "-rw-r--r-- 1 d4m d4m 6,4M mar  7 02:17 part-00003-1696d466-562a-4717-bc0c-78e0e6cc1ae9-c000.snappy.parquet\n",
      "-rw-r--r-- 1 d4m d4m 6,4M mar  7 02:17 part-00004-1696d466-562a-4717-bc0c-78e0e6cc1ae9-c000.snappy.parquet\n",
      "-rw-r--r-- 1 d4m d4m 6,4M mar  7 02:17 part-00005-1696d466-562a-4717-bc0c-78e0e6cc1ae9-c000.snappy.parquet\n",
      "-rw-r--r-- 1 d4m d4m    0 mar  7 02:17 _SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!ls -lh fhv/2019/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58989b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('data/pq/fhvhv/2021/02/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b01d2f",
   "metadata": {},
   "source": [
    "**Q3: How many taxi trips were there on October 15?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7489aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c2500fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62318"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .filter(\"pickup_date = '2019-10-15'\") \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd7ae60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('fhv_2019_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d47c147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   62318|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    COUNT(1)\n",
    "FROM \n",
    "    fhv_2019_10\n",
    "WHERE\n",
    "    to_date(pickup_datetime) = '2019-10-15';\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f533b",
   "metadata": {},
   "source": [
    "**Q4: Longest trip for each day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7befe422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropOff_datetime',\n",
       " 'PUlocationID',\n",
       " 'DOlocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "279d9161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|pickup_date|max(duration)|\n",
      "+-----------+-------------+\n",
      "| 2019-10-28|   2272149000|\n",
      "| 2019-10-11|   2272149000|\n",
      "| 2019-11-01|    315620787|\n",
      "| 2019-10-01|    252460901|\n",
      "| 2019-10-17|     31658400|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('duration', df.dropOff_datetime.cast('long') - df.pickup_datetime.cast('long')) \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .groupBy('pickup_date') \\\n",
    "        .max('duration') \\\n",
    "    .orderBy('max(duration)', ascending=False) \\\n",
    "    .limit(5) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "74cf0e8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 144:=============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|pickup_date|          duration|\n",
      "+-----------+------------------+\n",
      "| 2019-10-28|        3.786915E7|\n",
      "| 2019-10-11|        3.786915E7|\n",
      "| 2019-11-01|        5260346.45|\n",
      "| 2019-10-01| 4207681.683333334|\n",
      "| 2019-10-17|          527640.0|\n",
      "| 2019-10-26|          527050.0|\n",
      "| 2019-10-30| 87872.06666666667|\n",
      "| 2019-10-25|           63409.6|\n",
      "| 2019-10-02|47552.183333333334|\n",
      "| 2019-10-03| 46139.01666666667|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    to_date(pickup_datetime) AS pickup_date,\n",
    "    MAX((CAST(dropoff_datetime AS LONG) - CAST(pickup_datetime AS LONG)) / 60) AS duration\n",
    "FROM \n",
    "    fhv_2019_10\n",
    "GROUP BY\n",
    "    1\n",
    "ORDER BY\n",
    "    2 DESC\n",
    "LIMIT 10;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d915096b",
   "metadata": {},
   "source": [
    "**Q6: Least frequent pickup location zone**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f19f9257-b055-4c3a-b340-1a087ea20243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bab76277-31e3-47aa-8199-98d2abe2cc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78c16fe6-ad31-4076-aff7-e00d5483a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.createOrReplaceTempView('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "25816aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------+\n",
      "|LocationID|                Zone|count(1)|\n",
      "+----------+--------------------+--------+\n",
      "|         2|         Jamaica Bay|       1|\n",
      "|       105|Governor's Island...|       2|\n",
      "|       111| Green-Wood Cemetery|       5|\n",
      "|        30|       Broad Channel|       8|\n",
      "|       120|     Highbridge Park|      14|\n",
      "+----------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    LocationID,\n",
    "    Zone,\n",
    "    COUNT(1)\n",
    "FROM \n",
    "    fhv_2019_10\n",
    "JOIN zones \n",
    "ON fhv_2019_10.PUlocationID = zones.LocationID\n",
    "GROUP BY\n",
    "    LocationID,\n",
    "    Zone\n",
    "ORDER BY\n",
    "    3 ASC\n",
    "LIMIT 5;\n",
    "\"\"\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
